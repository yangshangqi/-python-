# 时间序列

时间序列（time series）数据是一种重要的结构化数据形式，应用于多个领域，包括金融学、经济学、生态学、神经科学、物理学等。在多个时间点观察或测量到的任何事物都可以形成一段时间序列。很多时间序列是固定频率的，也就是说，数据点是根据某种规律定期出现的（比如每15秒、每5分钟、每月出现一次）。时间序列也可以是不定期的，没有固定的时间单位或单位之间的偏移量。时间序列数据的意义取决于具体的应用场景，主要有以下几种：

时间戳（timestamp），特定的时刻。
固定时期（period），如2007年1月或2010年全年。
时间间隔（interval），由起始和结束时间戳表示。时期（period）可以被看做间隔（interval）的特例。
实验或过程时间，每个时间点都是相对于特定起始时间的一个度量。例如，从放入烤箱时起，每秒钟饼干的直径

## 一.日期和时间数据类型及工具

Python标准库包含用于日期（date）和时间（time）数据的数据类型，而且还有日历方面的功能。我们主要会用到datetime、time以及calendar模块。datetime.datetime（也可以简写为datetime）是用得最多的数据类型：


```python
from datetime import datetime
now = datetime.now()
now
```




    datetime.datetime(2020, 6, 12, 11, 1, 55, 725880)



datetime以毫秒形式存储日期和时间。timedelta表示两个datetime对象之间的时间差：


```python
delta = datetime(2011,1,7) - datetime(2008,6,24,8,15)
delta
```




    datetime.timedelta(days=926, seconds=56700)




```python
delta.days
```




    926




```python
delta.seconds
```




    56700



可以给datetime对象加上（或减去）一个或多个timedelta，这样会产生一个新对象：


```python
from datetime import timedelta
start = datetime(2011, 1, 7)
start + timedelta(12)
```




    datetime.datetime(2011, 1, 19, 0, 0)




```python
start - 2 * timedelta(12)
```




    datetime.datetime(2010, 12, 14, 0, 0)



datetime模块中的数据类型参见表10-1。虽然本章主要讲的是pandas数据类型和高级时间序列处理，但你肯定会在Python的其他地方遇到有关datetime的数据类型。

![](https://camo.githubusercontent.com/9f86270387f8b04bc10b63b98538264a8f359a47/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f373137383639312d346166323631613330356137306165622e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

### 1.1字符串与datetime互相转换

你可以使用str方法或传递一个指定的格式给strftime方法来将日期转化为字符串：


```python
stamp = datetime(2011, 1, 3)
str(stamp)
```




    '2011-01-03 00:00:00'




```python
stamp.strftime('%Y-%m-%d')
```




    '2011-01-03'



下表列出了全部的格式化编码

![](https://camo.githubusercontent.com/2ad68b9bd8863a4e86d903f6dd5cd2f70478fe49/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f373137383639312d646530313831653166366234356561662e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

datetime.strptime可以将字符串转换为日期：


```python
value = '2011-01-03'
datetime.strptime(value,'%Y-%m-%d')
```




    datetime.datetime(2011, 1, 3, 0, 0)




```python
datestrs = ['7/6/2011','8/6/2011']
[datetime.strptime(x,'%m/%d/%Y') for x in datestrs]
```




    [datetime.datetime(2011, 7, 6, 0, 0), datetime.datetime(2011, 8, 6, 0, 0)]



datetime.strptime是通过已知格式进行日期解析的最佳方式。但是每次都要编写格式定义是很麻烦的事情，尤其是对于一些常见的日期格式。这种情况下，你可以用dateutil这个第三方包中的parser.parse方法（pandas中已经自动安装好了）:


```python
from dateutil.parser import parse
parse('2011-01-03')
```




    datetime.datetime(2011, 1, 3, 0, 0)



dateutil可以解析几乎所有人类能够理解的日期表示形式：


```python
parse('Jan 31, 1997 10:45 PM')
```




    datetime.datetime(1997, 1, 31, 22, 45)



在国际通用的格式中，日出现在月的前面很普遍，传入dayfirst=True即可解决这个问题：


```python
parse('6/12/2011',dayfirst = True)
```




    datetime.datetime(2011, 12, 6, 0, 0)



pandas通常是用于处理成组日期的，不管这些日期是DataFrame的轴索引还是列。to_datetime方法可以解析多种不同的日期表示形式。对标准日期格式（如ISO8601）的解析非常快：


```python
import pandas as pd
datestrs = ['2011-07-06 12:00:00', '2011-08-06 00:00:00']
pd.to_datetime(datestrs)
```




    DatetimeIndex(['2011-07-06 12:00:00', '2011-08-06 00:00:00'], dtype='datetime64[ns]', freq=None)



它还可以处理缺失值（None、空字符串等）：


```python
idx = pd.to_datetime(datestrs + [None])
idx
```




    DatetimeIndex(['2011-07-06 12:00:00', '2011-08-06 00:00:00', 'NaT'], dtype='datetime64[ns]', freq=None)




```python
pd.isnull(idx)
```




    array([False, False,  True])



NaT（Not a Time）是pandas中时间戳数据的null值。

## 二.时间序列基础

pandas最基本的时间序列类型就是以时间戳为索引的Series：


```python
from datetime import datetime
import numpy as np
dates = [datetime(2011, 1, 2), datetime(2011, 1, 5),
         datetime(2011, 1, 7), datetime(2011, 1, 8),
         datetime(2011, 1, 10), datetime(2011, 1, 12)]
ts = pd.Series(np.random.randn(6),index = dates)
ts
```




    2011-01-02   -0.490098
    2011-01-05    0.187695
    2011-01-07   -0.055946
    2011-01-08   -0.702756
    2011-01-10    0.041756
    2011-01-12   -0.498802
    dtype: float64



这些datetime对象实际上是被放在一个DatetimeIndex中的：


```python
ts.index
```




    DatetimeIndex(['2011-01-02', '2011-01-05', '2011-01-07', '2011-01-08',
                   '2011-01-10', '2011-01-12'],
                  dtype='datetime64[ns]', freq=None)



跟其他Series一样，不同索引的时间序列之间的算术运算会自动按日期对齐：


```python
ts + ts[::2]
```




    2011-01-02   -0.980196
    2011-01-05         NaN
    2011-01-07   -0.111893
    2011-01-08         NaN
    2011-01-10    0.083512
    2011-01-12         NaN
    dtype: float64



pandas用NumPy的datetime64数据类型以纳秒形式存储时间戳：


```python
ts.index.dtype
```




    dtype('<M8[ns]')



DatetimeIndex中的各个标量值是pandas的Timestamp对象：


```python
stamp = ts.index[0]
stamp
```




    Timestamp('2011-01-02 00:00:00')



### 2.1索引、选取、子集构造

当你根据标签索引选取数据时，时间序列和其它的pandas.Series很像：


```python
stamp =ts.index[2]
ts[stamp]
```




    -0.055946269814280004



还有一种更为方便的用法：传入一个可以被解释为日期的字符串：


```python
ts['1/10/2011']
```




    0.041755990358559786



对于较长的时间序列，只需传入“年”或“年月”即可轻松选取数据的切片：


```python
longer_ts = pd.Series(np.random.randn(1000),
                      index=pd.date_range('1/1/2000', periods=1000))
longer_ts
```




    2000-01-01    0.430554
    2000-01-02    0.380936
    2000-01-03    0.231022
    2000-01-04    0.372946
    2000-01-05   -0.621854
                    ...   
    2002-09-22   -0.993284
    2002-09-23    0.787516
    2002-09-24   -0.282983
    2002-09-25   -0.223707
    2002-09-26    0.722171
    Freq: D, Length: 1000, dtype: float64




```python
longer_ts['2001']
```




    2001-01-01    1.820664
    2001-01-02    0.468122
    2001-01-03    0.031663
    2001-01-04   -0.429978
    2001-01-05   -1.231778
                    ...   
    2001-12-27    1.217553
    2001-12-28    1.620380
    2001-12-29   -0.473490
    2001-12-30    0.416489
    2001-12-31   -0.853678
    Freq: D, Length: 365, dtype: float64



这里，字符串“2001”被解释成年，并根据它选取时间区间。指定月也同样奏效：


```python
longer_ts['2001-05']
```




    2001-05-01   -1.050098
    2001-05-02    0.934629
    2001-05-03   -1.588342
    2001-05-04   -0.172362
    2001-05-05   -0.495130
    2001-05-06    0.320423
    2001-05-07    0.485818
    2001-05-08   -0.393771
    2001-05-09    1.194968
    2001-05-10    0.363793
    2001-05-11   -0.089614
    2001-05-12   -0.874196
    2001-05-13    1.262296
    2001-05-14    0.566894
    2001-05-15    0.974771
    2001-05-16   -1.872069
    2001-05-17    0.311915
    2001-05-18   -1.206606
    2001-05-19   -0.131080
    2001-05-20    0.094507
    2001-05-21   -0.945716
    2001-05-22   -0.994700
    2001-05-23    0.710939
    2001-05-24   -0.494992
    2001-05-25    0.146058
    2001-05-26    0.086497
    2001-05-27   -1.549632
    2001-05-28    1.314891
    2001-05-29    0.711736
    2001-05-30   -0.158198
    2001-05-31    0.369197
    Freq: D, dtype: float64



datetime对象也可以进行切片：


```python
ts[datetime(2011, 1, 7):]
```




    2011-01-07   -0.055946
    2011-01-08   -0.702756
    2011-01-10    0.041756
    2011-01-12   -0.498802
    dtype: float64



由于大部分时间序列数据都是按照时间先后排序的，因此你也可以用不存在于该时间序列中的时间戳对其进行切片（即范围查询）：


```python
ts
```




    2011-01-02   -0.490098
    2011-01-05    0.187695
    2011-01-07   -0.055946
    2011-01-08   -0.702756
    2011-01-10    0.041756
    2011-01-12   -0.498802
    dtype: float64




```python
ts['1/6/2011':'1/11/2011']
```




    2011-01-07   -0.055946
    2011-01-08   -0.702756
    2011-01-10    0.041756
    dtype: float64



跟之前一样，你可以传入字符串日期、datetime或Timestamp。注意，这样切片所产生的是原时间序列的视图，跟NumPy数组的切片运算是一样的。

这意味着，没有数据被复制，对切片进行修改会反映到原始数据上。

有一个等价的实例方法，truncate,它可以在俩个日期间对Series进行切片


```python
ts.truncate(after = '1/9/2011')
```




    2011-01-02   -0.490098
    2011-01-05    0.187695
    2011-01-07   -0.055946
    2011-01-08   -0.702756
    dtype: float64



这些操作对DataFrame也有效。例如，对DataFrame的行进行索引:


```python
dates = pd.date_range('1/1/2000', periods=100, freq='W-WED')
long_df = pd.DataFrame(np.random.randn(100, 4),index = dates,
                       columns=['Colorado', 'Texas','New York', 'Ohio'])
long_df.loc['5-2001']
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Colorado</th>
      <th>Texas</th>
      <th>New York</th>
      <th>Ohio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2001-05-02</td>
      <td>-1.044743</td>
      <td>0.583939</td>
      <td>0.770753</td>
      <td>-0.016473</td>
    </tr>
    <tr>
      <td>2001-05-09</td>
      <td>-0.388726</td>
      <td>-0.175726</td>
      <td>0.005953</td>
      <td>1.170192</td>
    </tr>
    <tr>
      <td>2001-05-16</td>
      <td>-0.509210</td>
      <td>-0.103736</td>
      <td>-0.701918</td>
      <td>-0.874472</td>
    </tr>
    <tr>
      <td>2001-05-23</td>
      <td>0.122732</td>
      <td>-0.826656</td>
      <td>0.162636</td>
      <td>-0.586785</td>
    </tr>
    <tr>
      <td>2001-05-30</td>
      <td>-0.844823</td>
      <td>-0.821345</td>
      <td>-1.276492</td>
      <td>0.825487</td>
    </tr>
  </tbody>
</table>
</div>



### 2.2 含有重复索引的时间序列

在某些应用场景中，可能会存在多个观测数据落在同一个时间点上的情况。下面就是一个例子：


```python
dates = pd.DatetimeIndex(['1/1/2000', '1/2/2000', '1/2/2000',
                          '1/2/2000', '1/3/2000'])
dup_ts = pd.Series(np.arange(5), index=dates)
dup_ts
```




    2000-01-01    0
    2000-01-02    1
    2000-01-02    2
    2000-01-02    3
    2000-01-03    4
    dtype: int32



通过检查索引的is_unique属性，我们就可以知道它是不是唯一的：


```python
dup_ts.index.is_unique
```




    False



对这个时间序列进行索引，要么产生标量值，要么产生切片，具体要看所选的时间点是否重复：


```python
dup_ts['1/3/2000']
```




    4




```python
dup_ts['1/2/2000']
```




    2000-01-02    1
    2000-01-02    2
    2000-01-02    3
    dtype: int32



假设你想要对具有非唯一时间戳的数据进行聚合。一个办法是使用groupby，并传入level=0：


```python
grouped = dup_ts.groupby(level=0)
grouped.mean()
```




    2000-01-01    0
    2000-01-02    2
    2000-01-03    4
    dtype: int32




```python
grouped.count()
```




    2000-01-01    1
    2000-01-02    3
    2000-01-03    1
    dtype: int64



## 三.日期的范围、频率以及移动

将时间序列以某种相对固定的频率进行分析，比如每日、每月、每15分钟等（这样自然会在时间序列中引入缺失值）。幸运的是，pandas有一整套标准时间序列频率以及用于重采样、频率推断、生成固定频率日期范围的工具。

例如，我们可以将之前那个时间序列转换为一个具有固定频率（每日）的时间序列，只需调用resample即可：


```python
ts
```




    2011-01-02   -0.490098
    2011-01-05    0.187695
    2011-01-07   -0.055946
    2011-01-08   -0.702756
    2011-01-10    0.041756
    2011-01-12   -0.498802
    dtype: float64




```python
resampler = ts.resample('D')
```

字符串“D”是每天的意思。

下面，我将告诉你如何使用基本的频率和它的倍数。

### 3.1生成日期范围

pandas.date_range可用于根据指定的频率生成指定长度的DatetimeIndex：


```python
index = pd.date_range('2012-04-01', '2012-06-01')
index
```




    DatetimeIndex(['2012-04-01', '2012-04-02', '2012-04-03', '2012-04-04',
                   '2012-04-05', '2012-04-06', '2012-04-07', '2012-04-08',
                   '2012-04-09', '2012-04-10', '2012-04-11', '2012-04-12',
                   '2012-04-13', '2012-04-14', '2012-04-15', '2012-04-16',
                   '2012-04-17', '2012-04-18', '2012-04-19', '2012-04-20',
                   '2012-04-21', '2012-04-22', '2012-04-23', '2012-04-24',
                   '2012-04-25', '2012-04-26', '2012-04-27', '2012-04-28',
                   '2012-04-29', '2012-04-30', '2012-05-01', '2012-05-02',
                   '2012-05-03', '2012-05-04', '2012-05-05', '2012-05-06',
                   '2012-05-07', '2012-05-08', '2012-05-09', '2012-05-10',
                   '2012-05-11', '2012-05-12', '2012-05-13', '2012-05-14',
                   '2012-05-15', '2012-05-16', '2012-05-17', '2012-05-18',
                   '2012-05-19', '2012-05-20', '2012-05-21', '2012-05-22',
                   '2012-05-23', '2012-05-24', '2012-05-25', '2012-05-26',
                   '2012-05-27', '2012-05-28', '2012-05-29', '2012-05-30',
                   '2012-05-31', '2012-06-01'],
                  dtype='datetime64[ns]', freq='D')



默认情况下，date_range的频率为1天。如果只传入起始或结束日期，那就还得传入一个表示数字表示生成多少个日期


```python
pd.date_range(start='2012-04-01', periods=20)
```




    DatetimeIndex(['2012-04-01', '2012-04-02', '2012-04-03', '2012-04-04',
                   '2012-04-05', '2012-04-06', '2012-04-07', '2012-04-08',
                   '2012-04-09', '2012-04-10', '2012-04-11', '2012-04-12',
                   '2012-04-13', '2012-04-14', '2012-04-15', '2012-04-16',
                   '2012-04-17', '2012-04-18', '2012-04-19', '2012-04-20'],
                  dtype='datetime64[ns]', freq='D')




```python
pd.date_range(end='2012-06-01', periods=20)
```




    DatetimeIndex(['2012-05-13', '2012-05-14', '2012-05-15', '2012-05-16',
                   '2012-05-17', '2012-05-18', '2012-05-19', '2012-05-20',
                   '2012-05-21', '2012-05-22', '2012-05-23', '2012-05-24',
                   '2012-05-25', '2012-05-26', '2012-05-27', '2012-05-28',
                   '2012-05-29', '2012-05-30', '2012-05-31', '2012-06-01'],
                  dtype='datetime64[ns]', freq='D')



起始和结束日期定义了日期索引的严格边界。例如，如果你想要生成一个由每月最后一个工作日组成的日期索引，可以传入"BM"频率（表示business end of month），这样就只会包含时间间隔内（或刚好在边界上的）符合频率要求的日期：


```python
pd.date_range('2000-01-01', '2000-12-01', freq='BM')
```




    DatetimeIndex(['2000-01-31', '2000-02-29', '2000-03-31', '2000-04-28',
                   '2000-05-31', '2000-06-30', '2000-07-31', '2000-08-31',
                   '2000-09-29', '2000-10-31', '2000-11-30'],
                  dtype='datetime64[ns]', freq='BM')



下表：基本的时间序列频率

![](https://camo.githubusercontent.com/a6be2c24dcd3db7deb39f571cc273ec41fbb15ba/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f373137383639312d633836313464646264313037393363612e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

![](https://camo.githubusercontent.com/571e975181671e1ababd22035ec082c5f724d075/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f373137383639312d386461343662613936353434623037312e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)
![](https://camo.githubusercontent.com/e6a53cd190932b0f2b6a8e8ab8bdb067afeb458b/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f373137383639312d336361343130363039313935656463342e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

date_range默认会保留起始和结束时间戳的时间信息（如果有的话）：


```python
pd.date_range('2012-05-02 12:56:31', periods=5)
```




    DatetimeIndex(['2012-05-02 12:56:31', '2012-05-03 12:56:31',
                   '2012-05-04 12:56:31', '2012-05-05 12:56:31',
                   '2012-05-06 12:56:31'],
                  dtype='datetime64[ns]', freq='D')



### 3.2频率和日期偏置

pandas中的频率是由一个基础频率和一个乘数组成的。基础频率通常以一个字符串别名表示，比如"M"表示每月，"H"表示每小时。对于每个基础频率，都有一个被称为日期偏移量（date offset）的对象与之对应。例如，按小时计算的频率可以用Hour类表示：


```python
from pandas.tseries.offsets import Hour, Minute
hour = Hour()
hour
```




    <Hour>



传入一个整数即可定义偏移量的倍数：


```python
four_hours = Hour(4)
four_hours
```




    <4 * Hours>



一般来说，无需明确创建这样的对象，只需使用诸如"H"或"4H"这样的字符串别名即可。在基础频率前面放上一个整数即可创建倍数：


```python
 pd.date_range('2000-01-01', '2000-01-03 23:59', freq='4h')
```




    DatetimeIndex(['2000-01-01 00:00:00', '2000-01-01 04:00:00',
                   '2000-01-01 08:00:00', '2000-01-01 12:00:00',
                   '2000-01-01 16:00:00', '2000-01-01 20:00:00',
                   '2000-01-02 00:00:00', '2000-01-02 04:00:00',
                   '2000-01-02 08:00:00', '2000-01-02 12:00:00',
                   '2000-01-02 16:00:00', '2000-01-02 20:00:00',
                   '2000-01-03 00:00:00', '2000-01-03 04:00:00',
                   '2000-01-03 08:00:00', '2000-01-03 12:00:00',
                   '2000-01-03 16:00:00', '2000-01-03 20:00:00'],
                  dtype='datetime64[ns]', freq='4H')



大部分偏移量对象都可通过加法进行连接：


```python
Hour(2) + Minute(30)
```




    <150 * Minutes>



同理，你也可以传入频率字符串（如"2h30min"），这种字符串可以被高效地解析为等效的表达式：


```python
pd.date_range('2000-01-01', periods=10, freq='1h30min')
```




    DatetimeIndex(['2000-01-01 00:00:00', '2000-01-01 01:30:00',
                   '2000-01-01 03:00:00', '2000-01-01 04:30:00',
                   '2000-01-01 06:00:00', '2000-01-01 07:30:00',
                   '2000-01-01 09:00:00', '2000-01-01 10:30:00',
                   '2000-01-01 12:00:00', '2000-01-01 13:30:00'],
                  dtype='datetime64[ns]', freq='90T')



有些频率所描述的时间点并不是均匀分隔的。例如，"M"（日历月末）和"BM"（每月最后一个工作日）就取决于每月的天数，对于后者，还要考虑月末是不是周末。由于没有更好的术语，我将这些称为锚点偏移量

**月中某星期的日期**

WOM（Week Of Month）是一种非常实用的频率类，它以WOM开头。它使你能获得诸如“每月第3个星期五”之类的日期：


```python
rng = pd.date_range('2012-01-01', '2012-09-01', freq='WOM-3FRI')
list(rng)
```




    [Timestamp('2012-01-20 00:00:00', freq='WOM-3FRI'),
     Timestamp('2012-02-17 00:00:00', freq='WOM-3FRI'),
     Timestamp('2012-03-16 00:00:00', freq='WOM-3FRI'),
     Timestamp('2012-04-20 00:00:00', freq='WOM-3FRI'),
     Timestamp('2012-05-18 00:00:00', freq='WOM-3FRI'),
     Timestamp('2012-06-15 00:00:00', freq='WOM-3FRI'),
     Timestamp('2012-07-20 00:00:00', freq='WOM-3FRI'),
     Timestamp('2012-08-17 00:00:00', freq='WOM-3FRI')]



### 3.3 移位(向前和向后日期)

移动（shifting）指的是沿着时间轴将数据前移或后移。Series和DataFrame都有一个shift方法用于执行单纯的前移或后移操作(mo默认向后移)，保持索引不变：


```python
 ts = pd.Series(np.random.randn(4),
                index=pd.date_range('1/1/2000', periods=4, freq='M'))
ts
```




    2000-01-31    0.743646
    2000-02-29    0.276474
    2000-03-31    1.121354
    2000-04-30   -1.235218
    Freq: M, dtype: float64




```python
ts.shift(2)
```




    2000-01-31         NaN
    2000-02-29         NaN
    2000-03-31    0.743646
    2000-04-30    0.276474
    Freq: M, dtype: float64



当我们这样进行移动时，就会在时间序列的前面或后面产生缺失数据。

由于单纯的移位操作不会修改索引，所以部分数据会被丢弃。因此，如果频率已知，则可以将其传给shift以便实现对时间戳进行位移而不是对数据进行简单位移：


```python
ts.shift(2, freq='M')
```




    2000-03-31    0.743646
    2000-04-30    0.276474
    2000-05-31    1.121354
    2000-06-30   -1.235218
    Freq: M, dtype: float64



这里还可以使用其他频率，于是你就能非常灵活地对数据进行超前和滞后处理了：


```python
ts.shift(3, freq='D')
```




    2000-02-03    0.743646
    2000-03-03    0.276474
    2000-04-03    1.121354
    2000-05-03   -1.235218
    dtype: float64



**使通过偏移量对日期进行位移**

pandas的日期偏移量还可以用在datetime或Timestamp对象上：


```python
from pandas.tseries.offsets import Day, MonthEnd
now = datetime(2011, 11, 17)
now + 3 * Day()
```




    Timestamp('2011-11-20 00:00:00')



如果加的是锚点偏移量（比如MonthEnd），第一次增量会将原日期向前滚动到符合频率规则的下一个日期：


```python
now + MonthEnd()
```




    Timestamp('2011-11-30 00:00:00')




```python
now + MonthEnd(2)
```




    Timestamp('2011-12-31 00:00:00')



通过锚点偏移量的rollforward和rollback方法，可明确地将日期向前或向后“滚动”：


```python
offset = MonthEnd()
```




    <MonthEnd>




```python
offset.rollforward(now)
```




    Timestamp('2011-11-30 00:00:00')




```python
offset.rollback(now)
```




    Timestamp('2011-10-31 00:00:00')



日期偏移量还有一个巧妙的用法，即结合groupby使用这两个“滚动”方法：


```python
ts = pd.Series(np.random.randn(20),
               index=pd.date_range('1/15/2000', periods=20, freq='4d'))
ts
```




    2000-01-15   -0.783096
    2000-01-19   -0.551214
    2000-01-23    1.185898
    2000-01-27    0.406999
    2000-01-31    0.046008
    2000-02-04    0.428412
    2000-02-08   -0.478000
    2000-02-12    0.490638
    2000-02-16    0.809444
    2000-02-20    1.132902
    2000-02-24    1.390530
    2000-02-28    2.247683
    2000-03-03   -0.990834
    2000-03-07   -0.818365
    2000-03-11   -1.329949
    2000-03-15    0.219291
    2000-03-19   -0.277743
    2000-03-23    0.713158
    2000-03-27    0.000280
    2000-03-31   -1.095116
    Freq: 4D, dtype: float64




```python
ts.groupby(offset.rollforward).mean()
```




    2000-01-31    0.060919
    2000-02-29    0.860230
    2000-03-31   -0.447410
    dtype: float64



更简单、更快速地实现该功能的办法是使用resample


```python
ts.resample('M').mean()
```




    2000-01-31    0.060919
    2000-02-29    0.860230
    2000-03-31   -0.447410
    Freq: M, dtype: float64



## 四.时区处理

时间序列处理工作中最让人不爽的就是对时区的处理。许多人都选择以协调世界时（UTC，它是格林尼治标准时间（Greenwich Mean Time）的接替者，目前已经是国际标准了）来处理时间序列。时区是以UTC偏移量的形式表示的。例如，夏令时期间，纽约比UTC慢4小时，而在全年其他时间则比UTC慢5小时。

在Python中，时区信息来自第三方库pytz，它使Python可以使用Olson数据库（汇编了世界时区信息）。这对历史数据非常重要，这是因为由于各地政府的各种突发奇想，夏令时转变日期（甚至UTC偏移量）已经发生过多次改变了。就拿美国来说，DST转变时间自1900年以来就改变过多次！

有关pytz库的更多信息，请查阅其文档。就本书而言，由于pandas包装了pytz的功能，因此你可以不用记忆其API，只要记得时区的名称即可。时区名可以在shell中看到，也可以通过文档查看：


```python
import pytz
pytz.common_timezones[-5:]
```




    ['US/Eastern', 'US/Hawaii', 'US/Mountain', 'US/Pacific', 'UTC']



要从pytz中获取时区对象，使用pytz.timezone即可：


```python
tz = pytz.timezone('America/New_York')
tz
```




    <DstTzInfo 'America/New_York' LMT-1 day, 19:04:00 STD>



pandas中的方法既可以接受时区名也可以接受这些对象。

### 4.1时区的本地化和转换

默认情况下，pandas中的时间序列是单纯的时区。看看下面这个时间序列：


```python
rng = pd.date_range('3/9/2012 9:30', periods=6, freq='M')
ts = pd.Series(np.random.randn(len(rng)), index=rng)
ts
```




    2012-03-31 09:30:00    0.417418
    2012-04-30 09:30:00   -0.351382
    2012-05-31 09:30:00   -2.643949
    2012-06-30 09:30:00    0.606721
    2012-07-31 09:30:00    1.447923
    2012-08-31 09:30:00    0.121825
    Freq: M, dtype: float64



其索引的tz字段为None：


```python
print(ts.index.tz)
```

    None
    

可以用时区集生成日期范围:


```python
pd.date_range('3/9/2012 9:30', periods=10, freq='D', tz='UTC')
```




    DatetimeIndex(['2012-03-09 09:30:00+00:00', '2012-03-10 09:30:00+00:00',
                   '2012-03-11 09:30:00+00:00', '2012-03-12 09:30:00+00:00',
                   '2012-03-13 09:30:00+00:00', '2012-03-14 09:30:00+00:00',
                   '2012-03-15 09:30:00+00:00', '2012-03-16 09:30:00+00:00',
                   '2012-03-17 09:30:00+00:00', '2012-03-18 09:30:00+00:00'],
                  dtype='datetime64[ns, UTC]', freq='D')



从单纯到本地化的转换是通过tz_localize方法处理的:


```python
ts
```




    2012-03-31 09:30:00    0.417418
    2012-04-30 09:30:00   -0.351382
    2012-05-31 09:30:00   -2.643949
    2012-06-30 09:30:00    0.606721
    2012-07-31 09:30:00    1.447923
    2012-08-31 09:30:00    0.121825
    Freq: M, dtype: float64




```python
ts_utc = ts.tz_localize('UTC')
ts_utc
```




    2012-03-31 09:30:00+00:00    0.417418
    2012-04-30 09:30:00+00:00   -0.351382
    2012-05-31 09:30:00+00:00   -2.643949
    2012-06-30 09:30:00+00:00    0.606721
    2012-07-31 09:30:00+00:00    1.447923
    2012-08-31 09:30:00+00:00    0.121825
    Freq: M, dtype: float64




```python
ts_utc.index
```




    DatetimeIndex(['2012-03-31 09:30:00+00:00', '2012-04-30 09:30:00+00:00',
                   '2012-05-31 09:30:00+00:00', '2012-06-30 09:30:00+00:00',
                   '2012-07-31 09:30:00+00:00', '2012-08-31 09:30:00+00:00'],
                  dtype='datetime64[ns, UTC]', freq='M')



一旦时间序列被本地化到某个特定时区，就可以用tz_convert将其转换到别的时区了：


```python
 ts_utc.tz_convert('America/New_York')
```




    2012-03-31 05:30:00-04:00    0.417418
    2012-04-30 05:30:00-04:00   -0.351382
    2012-05-31 05:30:00-04:00   -2.643949
    2012-06-30 05:30:00-04:00    0.606721
    2012-07-31 05:30:00-04:00    1.447923
    2012-08-31 05:30:00-04:00    0.121825
    Freq: M, dtype: float64



对于上面这种时间序列（它跨越了美国东部时区的夏令时转变期），我们可以将其本地化到EST，然后转换为UTC或柏林时间：


```python
ts_eastern = ts.tz_localize('America/New_York')
ts_eastern.tz_convert('UTC')
```




    2012-03-31 13:30:00+00:00    0.417418
    2012-04-30 13:30:00+00:00   -0.351382
    2012-05-31 13:30:00+00:00   -2.643949
    2012-06-30 13:30:00+00:00    0.606721
    2012-07-31 13:30:00+00:00    1.447923
    2012-08-31 13:30:00+00:00    0.121825
    Freq: M, dtype: float64




```python
ts_eastern.tz_convert('Europe/Berlin')
```




    2012-03-31 15:30:00+02:00    0.417418
    2012-04-30 15:30:00+02:00   -0.351382
    2012-05-31 15:30:00+02:00   -2.643949
    2012-06-30 15:30:00+02:00    0.606721
    2012-07-31 15:30:00+02:00    1.447923
    2012-08-31 15:30:00+02:00    0.121825
    Freq: M, dtype: float64



tz_localize和tz_convert也是DatetimeIndex的实例方法：


```python
ts.index.tz_localize('Asia/Shanghai')
```




    DatetimeIndex(['2012-03-31 09:30:00+08:00', '2012-04-30 09:30:00+08:00',
                   '2012-05-31 09:30:00+08:00', '2012-06-30 09:30:00+08:00',
                   '2012-07-31 09:30:00+08:00', '2012-08-31 09:30:00+08:00'],
                  dtype='datetime64[ns, Asia/Shanghai]', freq='M')



### 4.2时区感知时间戳对象的操作

跟时间序列和日期范围差不多，独立的Timestamp对象也可以从简单时间戳本地化为时区感知时间戳，并从一个时区转换到另一个时区：


```python
stamp = pd.Timestamp('2011-03-12 04:00')
stamp_utc = stamp.tz_localize('utc')
stamp_utc.tz_convert('America/New_York')
```




    Timestamp('2011-03-11 23:00:00-0500', tz='America/New_York')



在创建Timestamp时，还可以传入一个时区信息：


```python
stamp_moscow = pd.Timestamp('2011-03-12 04:00', tz='Europe/Moscow')
stamp_moscow
```




    Timestamp('2011-03-12 04:00:00+0300', tz='Europe/Moscow')



Timestamp对象在内部保存了一个UTC时间戳值（自UNIX纪元（1970年1月1日）算起的纳秒数）。这个UTC值在时区转换过程中是不会发生变化的：


```python
stamp_utc.value
```




    1299902400000000000




```python
stamp_utc.tz_convert('America/New_York').value
```




    1299902400000000000



当使用pandas的DateOffset对象执行时间算术运算时，运算过程会自动关注是否存在夏令时转变期。这里，我们创建了在DST转变之前的时间戳。首先，来看夏令时转变前的30分钟：


```python
from pandas.tseries.offsets import Hour
stamp = pd.Timestamp('2012-03-12 01:30', tz='US/Eastern')
stamp
```




    Timestamp('2012-03-12 01:30:00-0400', tz='US/Eastern')




```python
stamp + Hour()
```




    Timestamp('2012-03-12 02:30:00-0400', tz='US/Eastern')



然后，夏令时转变前90分钟：


```python
stamp = pd.Timestamp('2012-11-04 00:30', tz='US/Eastern')
stamp
```




    Timestamp('2012-11-04 00:30:00-0400', tz='US/Eastern')




```python
stamp + 2 * Hour()
```




    Timestamp('2012-11-04 01:30:00-0500', tz='US/Eastern')



### 4.3不用时区间的操作

如果两个时间序列的时区不同，在将它们合并到一起时，最终结果就会是UTC。由于时间戳其实是以UTC存储的，所以这是一个很简单的运算，并不需要发生任何转换：


```python
rng = pd.date_range('3/7/2012 9:30', periods=10, freq='B')
ts = pd.Series(np.random.randn(len(rng)), index=rng)
ts
```




    2012-03-07 09:30:00   -0.385625
    2012-03-08 09:30:00    1.454886
    2012-03-09 09:30:00    0.640163
    2012-03-12 09:30:00    0.462460
    2012-03-13 09:30:00    0.786484
    2012-03-14 09:30:00    0.886511
    2012-03-15 09:30:00    0.659433
    2012-03-16 09:30:00    0.781008
    2012-03-19 09:30:00    0.044516
    2012-03-20 09:30:00   -0.468984
    Freq: B, dtype: float64




```python
ts1 = ts[:7].tz_localize('Europe/London')
```


```python
ts2 = ts1[2:].tz_convert('Europe/Moscow')
```


```python
result = ts1 + ts2
result.index
```




    DatetimeIndex(['2012-03-07 09:30:00+00:00', '2012-03-08 09:30:00+00:00',
                   '2012-03-09 09:30:00+00:00', '2012-03-12 09:30:00+00:00',
                   '2012-03-13 09:30:00+00:00', '2012-03-14 09:30:00+00:00',
                   '2012-03-15 09:30:00+00:00'],
                  dtype='datetime64[ns, UTC]', freq='B')



## 五.时间区间和区间算术

时间区间表示的是时间范围，比如数日、数月、数季、数年等。Period类所表示的就是这种数据类型，其构造函数需要用到一个字符串或整数，以及频率：


```python
p = pd.Period(2007, freq='A-DEC')
p
```




    Period('2007', 'A-DEC')



这里，这个Period对象表示的是从2007年1月1日到2007年12月31日之间的整段时间。只需对Period对象加上或减去一个整数即可达到根据其频率进行位移的效果：


```python
p + 5
```




    Period('2012', 'A-DEC')




```python
p - 2
```




    Period('2005', 'A-DEC')



如果两个Period对象拥有相同的频率，则它们的差就是它们之间的单位数量：


```python
pd.Period('2014', freq='A-DEC') - p
```




    <7 * YearEnds: month=12>



period_range函数可用于创建规则的时期范围：


```python
rng = pd.period_range('2000-01-01', '2000-06-30', freq='M')
rng
```




    PeriodIndex(['2000-01', '2000-02', '2000-03', '2000-04', '2000-05', '2000-06'], dtype='period[M]', freq='M')



PeriodIndex类保存了一组Period，它可以在任何pandas数据结构中被用作轴索引：


```python
pd.Series(np.random.randn(6), index=rng)
```




    2000-01   -0.336145
    2000-02   -0.472274
    2000-03    0.143742
    2000-04   -1.358864
    2000-05    0.541279
    2000-06   -0.311676
    Freq: M, dtype: float64



如果你有一个字符串数组，你也可以使用PeriodIndex类：


```python
values = ['2001Q3', '2002Q2', '2003Q1']
index = pd.PeriodIndex(values, freq='Q-DEC')
index
```




    PeriodIndex(['2001Q3', '2002Q2', '2003Q1'], dtype='period[Q-DEC]', freq='Q-DEC')



### 5.1区间频率转换

Period和PeriodIndex对象都可以通过其asfreq方法被转换成别的频率。假设我们有一个年度时期，希望将其转换为当年年初或年末的一个月度时期。该任务非常简单：


```python
p = pd.Period('2007', freq='A-DEC')
p
```




    Period('2007', 'A-DEC')




```python
p.asfreq('M', how='start')
```




    Period('2007-01', 'M')




```python
p.asfreq('M', how='end')
```




    Period('2007-12', 'M')



你可以将Period('2007','A-DEC')看做一个被划分为多个月度时期的时间段中的游标。图11-1对此进行了说明。对于一个不以12月结束的财政年度，月度子时期的归属情况就不一样了：


```python
p = pd.Period('2007', freq='A-JUN')
p
```




    Period('2007', 'A-JUN')




```python
p.asfreq('M', 'start')
```




    Period('2006-07', 'M')




```python
p.asfreq('M', 'end')
```




    Period('2007-06', 'M')



![](https://camo.githubusercontent.com/48a64c472c396051eb37cbf2f105feb14cdc46ff/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f373137383639312d643230313230306430653635363736662e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

当你从高频率向低频率转换时，pandas根据子区间的‘所属’来决定父区间、例如，在A-JUN频率中，月份“2007年8月”实际上是属于周期“2008年”的：


```python
p = pd.Period('Aug-2007', 'M')
p.asfreq('A-JUN')
```




    Period('2008', 'A-JUN')



完整的PeriodIndex或TimeSeries的频率转换方式也是如此：


```python
rng = pd.period_range('2006', '2009', freq='A-DEC')
ts = pd.Series(np.random.randn(len(rng)), index=rng)
ts
```




    2006    0.329580
    2007    0.430259
    2008    0.955424
    2009    0.102444
    Freq: A-DEC, dtype: float64




```python
ts.asfreq('M', how='start')
```




    2006-01    0.329580
    2007-01    0.430259
    2008-01    0.955424
    2009-01    0.102444
    Freq: M, dtype: float64



这里，根据年度时期的第一个月，每年的时期被取代为每月的时期。如果我们想要每年的最后一个工作日，我们可以使用“B”频率，并指明想要该时期的末尾：


```python
ts.asfreq('B', how='end')
```




    2006-12-29    0.329580
    2007-12-31    0.430259
    2008-12-31    0.955424
    2009-12-31    0.102444
    Freq: B, dtype: float64



### 5.2季度区间频率

季度型数据在会计、金融等领域中很常见。许多季度型数据都会涉及“财年末”的概念，通常是一年12个月中某月的最后一个日历日或工作日。就这一点来说，时期"2012Q4"根据财年末的不同会有不同的含义。pandas支持12种可能的季度型频率，即Q-JAN到Q-DEC：


```python
p = pd.Period('2012Q4', freq='Q-JAN')
p
```




    Period('2012Q4', 'Q-JAN')



在以1月结束的财年中，2012Q4是从11月到1月（将其转换为日型频率就明白了）。图11-2对此进行了说明：


```python
p.asfreq('D', 'start')
```




    Period('2011-11-01', 'D')




```python
p.asfreq('D', 'end')
```




    Period('2012-01-31', 'D')



![](https://camo.githubusercontent.com/70c759db53aefd1dfd9e1aef417d05a24f1f8698/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f373137383639312d653265316435326339373636663666662e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

因此，Period之间的算术运算会非常简单。例如，要获取该季度倒数第二个工作日下午4点的时间戳，你可以这样：


```python
p4pm = (p.asfreq('B', 'e') - 1).asfreq('T', 's') + 16 * 60
p4pm
```




    Period('2012-01-30 16:00', 'T')




```python
p4pm.to_timestamp()
```




    Timestamp('2012-01-30 16:00:00')



period_range可用于生成季度型范围。季度型范围的算术运算也跟上面是一样的：


```python
rng = pd.period_range('2011Q3', '2012Q4', freq='Q-JAN')
ts = pd.Series(np.arange(len(rng)), index=rng)
ts
```




    2011Q3    0
    2011Q4    1
    2012Q1    2
    2012Q2    3
    2012Q3    4
    2012Q4    5
    Freq: Q-JAN, dtype: int32




```python
new_rng = (rng.asfreq('B', 'e') - 1).asfreq('T', 's') + 16 * 60
ts.index = new_rng.to_timestamp()
ts
```




    2010-10-28 16:00:00    0
    2011-01-28 16:00:00    1
    2011-04-28 16:00:00    2
    2011-07-28 16:00:00    3
    2011-10-28 16:00:00    4
    2012-01-30 16:00:00    5
    dtype: int32



### 5.3 将时间戳转换为区间(以及逆转换)

通过使用to_period方法，可以将由时间戳索引的Series和DataFrame对象转换为时期索引：


```python
rng = pd.date_range('2000-01-01', periods=3, freq='M')
ts = pd.Series(np.random.randn(3), index=rng)
ts
```




    2000-01-31   -1.227865
    2000-02-29    0.285097
    2000-03-31   -0.848557
    Freq: M, dtype: float64




```python
pts = ts.to_period()
pts
```




    2000-01   -1.227865
    2000-02    0.285097
    2000-03   -0.848557
    Freq: M, dtype: float64



由于时期指的是非重叠时间区间，因此对于给定的频率，一个时间戳只能属于一个时期。新PeriodIndex的频率默认是从时间戳推断而来的，你也可以指定任何别的频率。结果中允许存在重复时期：


```python
rng = pd.date_range('1/29/2000', periods=6, freq='D')
ts2 = pd.Series(np.random.randn(6), index=rng)
ts2
```




    2000-01-29   -0.947999
    2000-01-30   -0.517953
    2000-01-31    0.408502
    2000-02-01    0.738097
    2000-02-02   -0.591330
    2000-02-03   -0.646812
    Freq: D, dtype: float64




```python
ts2.to_period('M')
```




    2000-01   -0.947999
    2000-01   -0.517953
    2000-01    0.408502
    2000-02    0.738097
    2000-02   -0.591330
    2000-02   -0.646812
    Freq: M, dtype: float64



要转换回时间戳，使用to_timestamp即可：


```python
pts = ts2.to_period()
pts
```




    2000-01-29   -0.947999
    2000-01-30   -0.517953
    2000-01-31    0.408502
    2000-02-01    0.738097
    2000-02-02   -0.591330
    2000-02-03   -0.646812
    Freq: D, dtype: float64




```python
pts.to_timestamp(how='end')
```




    2000-01-29 23:59:59.999999999   -0.947999
    2000-01-30 23:59:59.999999999   -0.517953
    2000-01-31 23:59:59.999999999    0.408502
    2000-02-01 23:59:59.999999999    0.738097
    2000-02-02 23:59:59.999999999   -0.591330
    2000-02-03 23:59:59.999999999   -0.646812
    Freq: D, dtype: float64



### 5.4通过数组创建PeriodIndex

固定频率的数据集通常会将时间信息分开存放在多个列中。例如，在下面这个宏观经济数据集中，年度和季度就分别存放在不同的列中：


```python
data = pd.read_csv('../examples/macrodata.csv')
data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>quarter</th>
      <th>realgdp</th>
      <th>realcons</th>
      <th>realinv</th>
      <th>realgovt</th>
      <th>realdpi</th>
      <th>cpi</th>
      <th>m1</th>
      <th>tbilrate</th>
      <th>unemp</th>
      <th>pop</th>
      <th>infl</th>
      <th>realint</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1959.0</td>
      <td>1.0</td>
      <td>2710.349</td>
      <td>1707.4</td>
      <td>286.898</td>
      <td>470.045</td>
      <td>1886.9</td>
      <td>28.98</td>
      <td>139.7</td>
      <td>2.82</td>
      <td>5.8</td>
      <td>177.146</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1959.0</td>
      <td>2.0</td>
      <td>2778.801</td>
      <td>1733.7</td>
      <td>310.859</td>
      <td>481.301</td>
      <td>1919.7</td>
      <td>29.15</td>
      <td>141.7</td>
      <td>3.08</td>
      <td>5.1</td>
      <td>177.830</td>
      <td>2.34</td>
      <td>0.74</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1959.0</td>
      <td>3.0</td>
      <td>2775.488</td>
      <td>1751.8</td>
      <td>289.226</td>
      <td>491.260</td>
      <td>1916.4</td>
      <td>29.35</td>
      <td>140.5</td>
      <td>3.82</td>
      <td>5.3</td>
      <td>178.657</td>
      <td>2.74</td>
      <td>1.09</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1959.0</td>
      <td>4.0</td>
      <td>2785.204</td>
      <td>1753.7</td>
      <td>299.356</td>
      <td>484.052</td>
      <td>1931.3</td>
      <td>29.37</td>
      <td>140.0</td>
      <td>4.33</td>
      <td>5.6</td>
      <td>179.386</td>
      <td>0.27</td>
      <td>4.06</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1960.0</td>
      <td>1.0</td>
      <td>2847.699</td>
      <td>1770.5</td>
      <td>331.722</td>
      <td>462.199</td>
      <td>1955.5</td>
      <td>29.54</td>
      <td>139.6</td>
      <td>3.50</td>
      <td>5.2</td>
      <td>180.007</td>
      <td>2.31</td>
      <td>1.19</td>
    </tr>
  </tbody>
</table>
</div>



通过将这些数组以及一个频率传入PeriodIndex，就可以将它们合并成DataFrame的一个索引：


```python
index = pd.PeriodIndex(year=data.year, quarter=data.quarter,freq='Q-DEC')
index
```




    PeriodIndex(['1959Q1', '1959Q2', '1959Q3', '1959Q4', '1960Q1', '1960Q2',
                 '1960Q3', '1960Q4', '1961Q1', '1961Q2',
                 ...
                 '2007Q2', '2007Q3', '2007Q4', '2008Q1', '2008Q2', '2008Q3',
                 '2008Q4', '2009Q1', '2009Q2', '2009Q3'],
                dtype='period[Q-DEC]', length=203, freq='Q-DEC')




```python
data.index = index
data.infl
```




    1959Q1    0.00
    1959Q2    2.34
    1959Q3    2.74
    1959Q4    0.27
    1960Q1    2.31
              ... 
    2008Q3   -3.16
    2008Q4   -8.79
    2009Q1    0.94
    2009Q2    3.37
    2009Q3    3.56
    Freq: Q-DEC, Name: infl, Length: 203, dtype: float64



## 六.重新采样与频率交换

重新采样指的是将时间序列从一个频率转换到另一个频率的处理过程。将高频率数据聚合到低频率称为向下采样，而将低频率数据转换到高频率则称为向上采样。并不是所有的重采样都能被划分到这两个大类中。例如，将W-WED（每周三）转换为W-FRI既不是降采样也不是升采样。

pandas对象都带有一个resample方法，它是各种频率转换工作的主力函数。resample有一个类似于groupby的API，调用resample可以分组数据，然后会调用一个聚合函数：


```python
rng = pd.date_range('2000-01-01', periods=100, freq='D')
ts = pd.Series(np.random.randn(len(rng)), index=rng)
ts
```




    2000-01-01    0.456139
    2000-01-02    0.502745
    2000-01-03   -0.352648
    2000-01-04    0.521248
    2000-01-05    0.808494
                    ...   
    2000-04-05   -0.605629
    2000-04-06   -0.233667
    2000-04-07    1.788790
    2000-04-08    0.942432
    2000-04-09    0.455432
    Freq: D, Length: 100, dtype: float64




```python
ts.resample('M').mean()
```




    2000-01-31    0.043449
    2000-02-29   -0.166833
    2000-03-31    0.048763
    2000-04-30   -0.054643
    Freq: M, dtype: float64




```python
ts.resample('M', kind='period').mean()
```




    2000-01    0.043449
    2000-02   -0.166833
    2000-03    0.048763
    2000-04   -0.054643
    Freq: M, dtype: float64



resample是一个灵活高效的方法，可用于处理非常大的时间序列。我将通过一系列的示例说明其用法。下表总结它的一些选项。

![](https://camo.githubusercontent.com/a4706e8956169df487cf94011a64c3e9cb1ce25d/68747470733a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f373137383639312d623430613537303836633930346538332e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

### 6.1向下采样

将数据聚合到一个规则的低频率是一个常见的时间序列处理任务。待聚合的数据不必拥有固定的频率，期望的频率会自动定义聚合的面元边界，这些面元用于将时间序列拆分为多个片段。例如，要转换到月度频率（'M'或'BM'），数据需要被划分到多个单月时间段中。各时间段都是半开放的。一个数据点只能属于一个时间段，所有时间段的并集必须能组成整个时间帧。在用resample对数据进行降采样时，需要考虑两样东西：

各区间哪边是闭合的。

如何在间隔的起始或结束位置标记每个已聚合的箱体


```python
rng = pd.date_range('2000-01-01', periods=12, freq='T')
ts = pd.Series(np.arange(12), index=rng)
ts
```




    2000-01-01 00:00:00     0
    2000-01-01 00:01:00     1
    2000-01-01 00:02:00     2
    2000-01-01 00:03:00     3
    2000-01-01 00:04:00     4
    2000-01-01 00:05:00     5
    2000-01-01 00:06:00     6
    2000-01-01 00:07:00     7
    2000-01-01 00:08:00     8
    2000-01-01 00:09:00     9
    2000-01-01 00:10:00    10
    2000-01-01 00:11:00    11
    Freq: T, dtype: int32



假设你想让这些数据'五分钟'为一组进行求和：


```python
ts.resample('5min', closed='right').sum()
```




    1999-12-31 23:55:00     0
    2000-01-01 00:00:00    15
    2000-01-01 00:05:00    40
    2000-01-01 00:10:00    11
    Freq: 5T, dtype: int32



传入的频率将会以“5分钟”的增量定义箱体边界。默认情况下，箱体的左边界是包含的，因此00:00到00:05的区间中是包含00:00的。传入closed='right'会将区间的闭合端改为右边.

如你所见，最终的时间序列是以每个箱体的左边界的时间戳进行标记的。传入label='right'即可用每个箱体的右边界对其进行标记：


```python
ts.resample('5min', closed='right', label='right').sum()
```




    2000-01-01 00:00:00     0
    2000-01-01 00:05:00    15
    2000-01-01 00:10:00    40
    2000-01-01 00:15:00    11
    Freq: 5T, dtype: int32



上个例子说明了由“1分钟”数据被转换为“5分钟”数据的处理过程。

最后，你可能希望对结果索引做一些位移，比如从右边界减去一秒以便更容易明白该时间戳到底表示的是哪个区间。只需通过loffset设置一个字符串或日期偏移量即可实现这个目的：


```python
ts.resample('5min', closed='right',
            label='right', loffset='-1s').sum()
```




    1999-12-31 23:59:59     0
    2000-01-01 00:04:59    15
    2000-01-01 00:09:59    40
    2000-01-01 00:14:59    11
    Freq: 5T, dtype: int32



此外，也可以通过调用结果对象的shift方法来实现该目的，这样就不需要设置loffset了

**OHLC重采样**

金融领域中有一种无所不在的时间序列聚合方式，即计算各面元的四个值：第一个值（open，开端）、最后一个值（close，结束）、最大值（峰值）以及最小值（谷值）。传入how='ohlc'即可得到一个含有这四种聚合值的DataFrame。整个过程很高效，只需一次扫描即可计算出结果：


```python
ts.resample('5min').ohlc()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>open</th>
      <th>high</th>
      <th>low</th>
      <th>close</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2000-01-01 00:00:00</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>4</td>
    </tr>
    <tr>
      <td>2000-01-01 00:05:00</td>
      <td>5</td>
      <td>9</td>
      <td>5</td>
      <td>9</td>
    </tr>
    <tr>
      <td>2000-01-01 00:10:00</td>
      <td>10</td>
      <td>11</td>
      <td>10</td>
      <td>11</td>
    </tr>
  </tbody>
</table>
</div>



### 6.2向上采样与插值

在将数据从低频率转换到高频率时，就不需要聚合了。我们来看一个带有每周数据的DataFrame：


```python
frame = pd.DataFrame(np.random.randn(2, 4),
                     index=pd.date_range('1/1/2000', periods=2,freq='W-WED'),
                     columns=['Colorado', 'Texas', 'New York', 'Ohio'])
frame
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Colorado</th>
      <th>Texas</th>
      <th>New York</th>
      <th>Ohio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2000-01-05</td>
      <td>0.195338</td>
      <td>0.161317</td>
      <td>0.347014</td>
      <td>0.93643</td>
    </tr>
    <tr>
      <td>2000-01-12</td>
      <td>-0.927495</td>
      <td>-0.624667</td>
      <td>-0.294230</td>
      <td>-0.32329</td>
    </tr>
  </tbody>
</table>
</div>



当你对这个数据进行聚合，每组只有一个值，这样就会引入缺失值。我们使用asfreq方法转换成高频，不经过聚合：


```python
df_daily = frame.resample('D').asfreq()
df_daily
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Colorado</th>
      <th>Texas</th>
      <th>New York</th>
      <th>Ohio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2000-01-05</td>
      <td>0.195338</td>
      <td>0.161317</td>
      <td>0.347014</td>
      <td>0.93643</td>
    </tr>
    <tr>
      <td>2000-01-06</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>2000-01-07</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>2000-01-08</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>2000-01-09</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>2000-01-10</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>2000-01-11</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>2000-01-12</td>
      <td>-0.927495</td>
      <td>-0.624667</td>
      <td>-0.294230</td>
      <td>-0.32329</td>
    </tr>
  </tbody>
</table>
</div>



假设你想要在“非星期三”的日期上向前对齐填充每周数值。可使用ffill()方法


```python
frame.resample('D').ffill()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Colorado</th>
      <th>Texas</th>
      <th>New York</th>
      <th>Ohio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2000-01-05</td>
      <td>0.195338</td>
      <td>0.161317</td>
      <td>0.347014</td>
      <td>0.93643</td>
    </tr>
    <tr>
      <td>2000-01-06</td>
      <td>0.195338</td>
      <td>0.161317</td>
      <td>0.347014</td>
      <td>0.93643</td>
    </tr>
    <tr>
      <td>2000-01-07</td>
      <td>0.195338</td>
      <td>0.161317</td>
      <td>0.347014</td>
      <td>0.93643</td>
    </tr>
    <tr>
      <td>2000-01-08</td>
      <td>0.195338</td>
      <td>0.161317</td>
      <td>0.347014</td>
      <td>0.93643</td>
    </tr>
    <tr>
      <td>2000-01-09</td>
      <td>0.195338</td>
      <td>0.161317</td>
      <td>0.347014</td>
      <td>0.93643</td>
    </tr>
    <tr>
      <td>2000-01-10</td>
      <td>0.195338</td>
      <td>0.161317</td>
      <td>0.347014</td>
      <td>0.93643</td>
    </tr>
    <tr>
      <td>2000-01-11</td>
      <td>0.195338</td>
      <td>0.161317</td>
      <td>0.347014</td>
      <td>0.93643</td>
    </tr>
    <tr>
      <td>2000-01-12</td>
      <td>-0.927495</td>
      <td>-0.624667</td>
      <td>-0.294230</td>
      <td>-0.32329</td>
    </tr>
  </tbody>
</table>
</div>



同样，这里也可以只向前填充指定的数量的区间，以限制继续使用观测值的时距：


```python
frame.resample('D').ffill(limit=2)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Colorado</th>
      <th>Texas</th>
      <th>New York</th>
      <th>Ohio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2000-01-05</td>
      <td>0.195338</td>
      <td>0.161317</td>
      <td>0.347014</td>
      <td>0.93643</td>
    </tr>
    <tr>
      <td>2000-01-06</td>
      <td>0.195338</td>
      <td>0.161317</td>
      <td>0.347014</td>
      <td>0.93643</td>
    </tr>
    <tr>
      <td>2000-01-07</td>
      <td>0.195338</td>
      <td>0.161317</td>
      <td>0.347014</td>
      <td>0.93643</td>
    </tr>
    <tr>
      <td>2000-01-08</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>2000-01-09</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>2000-01-10</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>2000-01-11</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>2000-01-12</td>
      <td>-0.927495</td>
      <td>-0.624667</td>
      <td>-0.294230</td>
      <td>-0.32329</td>
    </tr>
  </tbody>
</table>
</div>



注意，新的日期索引完全没必要跟旧的重叠：


```python
frame.resample('W-THU').ffill()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Colorado</th>
      <th>Texas</th>
      <th>New York</th>
      <th>Ohio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2000-01-06</td>
      <td>0.195338</td>
      <td>0.161317</td>
      <td>0.347014</td>
      <td>0.93643</td>
    </tr>
    <tr>
      <td>2000-01-13</td>
      <td>-0.927495</td>
      <td>-0.624667</td>
      <td>-0.294230</td>
      <td>-0.32329</td>
    </tr>
  </tbody>
</table>
</div>



### 6.3使用区间进行重新采样

对以区间为索引的数据进行采样与时间戳的情况类似：


```python
frame = pd.DataFrame(np.random.randn(24, 4),
                     index=pd.period_range('1-2000', '12-2001',freq='M'),
                     columns=['Colorado', 'Texas', 'New York', 'Ohio'])
frame[:5]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Colorado</th>
      <th>Texas</th>
      <th>New York</th>
      <th>Ohio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2000-01</td>
      <td>2.990173</td>
      <td>0.991859</td>
      <td>-0.697586</td>
      <td>-0.059691</td>
    </tr>
    <tr>
      <td>2000-02</td>
      <td>2.000879</td>
      <td>-0.896114</td>
      <td>-0.272157</td>
      <td>0.840265</td>
    </tr>
    <tr>
      <td>2000-03</td>
      <td>-0.397523</td>
      <td>-0.065978</td>
      <td>1.209826</td>
      <td>0.379422</td>
    </tr>
    <tr>
      <td>2000-04</td>
      <td>-1.345548</td>
      <td>-0.597146</td>
      <td>-1.342359</td>
      <td>0.832733</td>
    </tr>
    <tr>
      <td>2000-05</td>
      <td>-0.760218</td>
      <td>-0.566524</td>
      <td>-0.189195</td>
      <td>-0.413799</td>
    </tr>
  </tbody>
</table>
</div>




```python
annual_frame = frame.resample('A-DEC').mean()
annual_frame
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Colorado</th>
      <th>Texas</th>
      <th>New York</th>
      <th>Ohio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2000</td>
      <td>-0.077562</td>
      <td>0.051488</td>
      <td>-0.070538</td>
      <td>0.178218</td>
    </tr>
    <tr>
      <td>2001</td>
      <td>-0.281588</td>
      <td>0.298583</td>
      <td>0.073033</td>
      <td>-0.222913</td>
    </tr>
  </tbody>
</table>
</div>



向上采样要稍微麻烦一些，因为你必须在重新采样前决定在新频率中各区间的哪端用于放置数值，就像asfreq方法那样。convention参数默认为'start'，也可设置为'end'：


```python
annual_frame.resample('Q-DEC').ffill()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Colorado</th>
      <th>Texas</th>
      <th>New York</th>
      <th>Ohio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2000Q1</td>
      <td>-0.077562</td>
      <td>0.051488</td>
      <td>-0.070538</td>
      <td>0.178218</td>
    </tr>
    <tr>
      <td>2000Q2</td>
      <td>-0.077562</td>
      <td>0.051488</td>
      <td>-0.070538</td>
      <td>0.178218</td>
    </tr>
    <tr>
      <td>2000Q3</td>
      <td>-0.077562</td>
      <td>0.051488</td>
      <td>-0.070538</td>
      <td>0.178218</td>
    </tr>
    <tr>
      <td>2000Q4</td>
      <td>-0.077562</td>
      <td>0.051488</td>
      <td>-0.070538</td>
      <td>0.178218</td>
    </tr>
    <tr>
      <td>2001Q1</td>
      <td>-0.281588</td>
      <td>0.298583</td>
      <td>0.073033</td>
      <td>-0.222913</td>
    </tr>
    <tr>
      <td>2001Q2</td>
      <td>-0.281588</td>
      <td>0.298583</td>
      <td>0.073033</td>
      <td>-0.222913</td>
    </tr>
    <tr>
      <td>2001Q3</td>
      <td>-0.281588</td>
      <td>0.298583</td>
      <td>0.073033</td>
      <td>-0.222913</td>
    </tr>
    <tr>
      <td>2001Q4</td>
      <td>-0.281588</td>
      <td>0.298583</td>
      <td>0.073033</td>
      <td>-0.222913</td>
    </tr>
  </tbody>
</table>
</div>




```python
annual_frame.resample('Q-DEC', convention='end').ffill()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Colorado</th>
      <th>Texas</th>
      <th>New York</th>
      <th>Ohio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2000Q4</td>
      <td>-0.077562</td>
      <td>0.051488</td>
      <td>-0.070538</td>
      <td>0.178218</td>
    </tr>
    <tr>
      <td>2001Q1</td>
      <td>-0.077562</td>
      <td>0.051488</td>
      <td>-0.070538</td>
      <td>0.178218</td>
    </tr>
    <tr>
      <td>2001Q2</td>
      <td>-0.077562</td>
      <td>0.051488</td>
      <td>-0.070538</td>
      <td>0.178218</td>
    </tr>
    <tr>
      <td>2001Q3</td>
      <td>-0.077562</td>
      <td>0.051488</td>
      <td>-0.070538</td>
      <td>0.178218</td>
    </tr>
    <tr>
      <td>2001Q4</td>
      <td>-0.281588</td>
      <td>0.298583</td>
      <td>0.073033</td>
      <td>-0.222913</td>
    </tr>
  </tbody>
</table>
</div>



由于区间涉及时间范围，所以向上采样和向下采样的规则就比较严格：

在向下采样中，目标频率必须是源频率的子区间。

在向上采样中，目标频率必须是源频率的父区间。

如果不满足这些条件，就会引发异常。这主要影响的是按季、年、周计算的频率。例如，由Q-MAR定义的时间区间只能升采样为A-MAR、A-JUN、A-SEP、A-DEC等：


```python
annual_frame.resample('Q-MAR').ffill()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Colorado</th>
      <th>Texas</th>
      <th>New York</th>
      <th>Ohio</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2000Q4</td>
      <td>-0.077562</td>
      <td>0.051488</td>
      <td>-0.070538</td>
      <td>0.178218</td>
    </tr>
    <tr>
      <td>2001Q1</td>
      <td>-0.077562</td>
      <td>0.051488</td>
      <td>-0.070538</td>
      <td>0.178218</td>
    </tr>
    <tr>
      <td>2001Q2</td>
      <td>-0.077562</td>
      <td>0.051488</td>
      <td>-0.070538</td>
      <td>0.178218</td>
    </tr>
    <tr>
      <td>2001Q3</td>
      <td>-0.077562</td>
      <td>0.051488</td>
      <td>-0.070538</td>
      <td>0.178218</td>
    </tr>
    <tr>
      <td>2001Q4</td>
      <td>-0.281588</td>
      <td>0.298583</td>
      <td>0.073033</td>
      <td>-0.222913</td>
    </tr>
    <tr>
      <td>2002Q1</td>
      <td>-0.281588</td>
      <td>0.298583</td>
      <td>0.073033</td>
      <td>-0.222913</td>
    </tr>
    <tr>
      <td>2002Q2</td>
      <td>-0.281588</td>
      <td>0.298583</td>
      <td>0.073033</td>
      <td>-0.222913</td>
    </tr>
    <tr>
      <td>2002Q3</td>
      <td>-0.281588</td>
      <td>0.298583</td>
      <td>0.073033</td>
      <td>-0.222913</td>
    </tr>
  </tbody>
</table>
</div>



## 七.移动窗口函数

统计和其他通过移动窗口或指数衰减而运行的函数也是一类常见于时间序列的数组变换。这对粗糙的数据十分有用。我将它们称为移动窗口函数（moving window function），其中还包括那些窗口不定长的函数（如指数加权移动平均）。跟其他统计函数一样，移动窗口函数也会自动排除缺失值。

开始之前，我们加载一些时间序列数据，将其重采样为工作日频率：


```python
close_px_all = pd.read_csv('../examples/stock_px_2.csv',
                           parse_dates=True, index_col=0)
close_px_all.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AAPL</th>
      <th>MSFT</th>
      <th>XOM</th>
      <th>SPX</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2003-01-02</td>
      <td>7.40</td>
      <td>21.11</td>
      <td>29.22</td>
      <td>909.03</td>
    </tr>
    <tr>
      <td>2003-01-03</td>
      <td>7.45</td>
      <td>21.14</td>
      <td>29.24</td>
      <td>908.59</td>
    </tr>
    <tr>
      <td>2003-01-06</td>
      <td>7.45</td>
      <td>21.52</td>
      <td>29.96</td>
      <td>929.01</td>
    </tr>
    <tr>
      <td>2003-01-07</td>
      <td>7.43</td>
      <td>21.93</td>
      <td>28.95</td>
      <td>922.93</td>
    </tr>
    <tr>
      <td>2003-01-08</td>
      <td>7.28</td>
      <td>21.31</td>
      <td>28.83</td>
      <td>909.93</td>
    </tr>
  </tbody>
</table>
</div>




```python
close_px = close_px_all[['AAPL', 'MSFT', 'XOM']]
close_px = close_px.resample('B').ffill()
```

现在引入rolling运算符，它与resample和groupby很像。可以在Series或DataFrame上通过window（以一个区间的数字来表示）进行调用：


```python
close_px.AAPL.plot()
close_px.AAPL.rolling(250).mean().plot()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x17046d6b5c8>




![png](1.%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%B7%A5%E5%85%B7_files/1.%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%B7%A5%E5%85%B7_286_1.png)


表达式rolling(250)与groupby很像，但不是对其进行分组，而是创建一个按照250天分组的滑动窗口对象。然后，我们就得到了苹果公司股价的250天的移动窗口平均值。

默认情况下，rolling函数需要窗口中所有的值为非NA值。由于存在缺失值这种行为会发生改变，尤其是在时间序列的起始位置你拥有的数据是少于窗口区间的


```python
appl_std250 = close_px.AAPL.rolling(250, min_periods=10).std()
appl_std250[5:12]
```




    2003-01-09         NaN
    2003-01-10         NaN
    2003-01-13         NaN
    2003-01-14         NaN
    2003-01-15    0.077496
    2003-01-16    0.074760
    2003-01-17    0.112368
    Freq: B, Name: AAPL, dtype: float64




```python
appl_std250.plot()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x17047f4b8c8>




![png](1.%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%B7%A5%E5%85%B7_files/1.%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%B7%A5%E5%85%B7_290_1.png)


要计算扩展窗口均值，可以使用expanding而不是rolling。扩展均值从时间序列的起始处开始时间窗口，增加窗口直到它超过所有的序列。apple_std250扩展窗口均值如下所示：


```python
expanding_mean = appl_std250.expanding().mean()
```

对DataFrame调用rolling-mean（以及与之类似的函数）会将转换应用到所有的列上


```python
close_px.rolling(60).mean().plot(logy=True)
```




    <matplotlib.axes._subplots.AxesSubplot at 0x170480492c8>




![png](1.%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%B7%A5%E5%85%B7_files/1.%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%B7%A5%E5%85%B7_294_1.png)


rolling函数也可以接受一个指定固定大小时间偏置字符串，而不是一个区间的集合数字。这样可以方便处理不规律的时间序列。这些字符串也可以传递给resample。例如，我们可以计算20天的滚动均值，如下所示：


```python
close_px.rolling('20D').mean()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>AAPL</th>
      <th>MSFT</th>
      <th>XOM</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2003-01-02</td>
      <td>7.400000</td>
      <td>21.110000</td>
      <td>29.220000</td>
    </tr>
    <tr>
      <td>2003-01-03</td>
      <td>7.425000</td>
      <td>21.125000</td>
      <td>29.230000</td>
    </tr>
    <tr>
      <td>2003-01-06</td>
      <td>7.433333</td>
      <td>21.256667</td>
      <td>29.473333</td>
    </tr>
    <tr>
      <td>2003-01-07</td>
      <td>7.432500</td>
      <td>21.425000</td>
      <td>29.342500</td>
    </tr>
    <tr>
      <td>2003-01-08</td>
      <td>7.402000</td>
      <td>21.402000</td>
      <td>29.240000</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <td>2011-10-10</td>
      <td>389.351429</td>
      <td>25.602143</td>
      <td>72.527857</td>
    </tr>
    <tr>
      <td>2011-10-11</td>
      <td>388.505000</td>
      <td>25.674286</td>
      <td>72.835000</td>
    </tr>
    <tr>
      <td>2011-10-12</td>
      <td>388.531429</td>
      <td>25.810000</td>
      <td>73.400714</td>
    </tr>
    <tr>
      <td>2011-10-13</td>
      <td>388.826429</td>
      <td>25.961429</td>
      <td>73.905000</td>
    </tr>
    <tr>
      <td>2011-10-14</td>
      <td>391.038000</td>
      <td>26.048667</td>
      <td>74.185333</td>
    </tr>
  </tbody>
</table>
<p>2292 rows × 3 columns</p>
</div>



### 7.1指数加权函数

指定一个常数衰减因子以向更多近期观测值提供更多权重，可以替代使用具有相等加权观测值的静态窗口尺寸的方法。衰减因子的定义方式有很多，比较流行的是使用时间间隔（span），它可以使结果兼容于窗口大小等于时间间隔的简单移动窗口（simple moving window）函数。

由于指数加权统计会赋予近期的观测值更大的权数，因此相对于等权统计，它能“适应”更快的变化。

除了rolling和expanding，pandas还有ewm运算符。下面这个例子对比了苹果公司股价的30日移动平均和span=30的指数加权移动平均：


```python
aapl_px = close_px.AAPL['2006':'2007']
ma60 = aapl_px.rolling(30, min_periods=20).mean()
ewma60 = aapl_px.ewm(span=30).mean()
```


```python
ma60.plot(style='k--', label='Simple MA')
```




    <matplotlib.axes._subplots.AxesSubplot at 0x170482ae6c8>




![png](1.%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%B7%A5%E5%85%B7_files/1.%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%B7%A5%E5%85%B7_302_1.png)



```python
ewma60.plot(style='k-', label='EW MA')
```




    <matplotlib.axes._subplots.AxesSubplot at 0x17048001b48>




![png](1.%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%B7%A5%E5%85%B7_files/1.%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%B7%A5%E5%85%B7_303_1.png)


### 7.2二元移动窗口函数

有些统计运算（如相关系数和协方差）需要在两个时间序列上执行。例如，金融分析师常常对某只股票对某个参考指数（如标准普尔500指数）的相关系数感兴趣。要进行说明，我们先计算我们感兴趣的时间序列的百分数变化：


```python
spx_px = close_px_all['SPX']
spx_rets = spx_px.pct_change()
returns = close_px.pct_change()
```

调用rolling之后，corr聚合函数开始计算与spx_rets滚动相关系数


```python
corr = returns.AAPL.rolling(125, min_periods=100).corr(spx_rets)
corr.plot()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x1704873a9c8>




![png](1.%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%B7%A5%E5%85%B7_files/1.%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%B7%A5%E5%85%B7_308_1.png)


假设你想要一次性计算多只股票与标准普尔500指数的相关系数。虽然编写一个循环并新建一个DataFrame不是什么难事，但比较啰嗦。其实，只需传入一个TimeSeries和一个DataFrame，rolling-corr就会自动计算Series（本例中就是spx_rets）与DataFrame各列的相关系数。


```python
corr = returns.rolling(125, min_periods=100).corr(spx_rets)
corr.plot()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x1704849fa08>




![png](1.%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%B7%A5%E5%85%B7_files/1.%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%B7%A5%E5%85%B7_310_1.png)


### 7用户自定义的移动窗口函数

rolling_apply函数使你能够在移动窗口上应用自己设计的数组函数。唯一要求的就是：该函数要能从数组的各个片段中产生单个值（即约简）。比如说，当我们用rolling(...).quantile(q)计算样本分位数时，可能对样本中特定值的百分等级感兴趣。scipy.stats.percentileofscore函数就能达到这个目的：


```python
from scipy.stats import percentileofscore
score_at_2percent = lambda x: percentileofscore(x, 0.02)
result = returns.AAPL.rolling(250).apply(score_at_2percent)
result.plot()
```

    C:\Users\Administrator\Anaconda3\lib\site-packages\ipykernel_launcher.py:3: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning
      This is separate from the ipykernel package so we can avoid doing imports until
    




    <matplotlib.axes._subplots.AxesSubplot at 0x1704a374448>




![png](1.%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%B7%A5%E5%85%B7_files/1.%E6%97%A5%E6%9C%9F%E5%92%8C%E6%97%B6%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E5%B7%A5%E5%85%B7_313_2.png)



```python

```
